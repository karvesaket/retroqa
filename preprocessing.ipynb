{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karvesaket/retroqa/blob/master/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rpoi-ovDr-az",
        "colab_type": "code",
        "outputId": "7d7f25ad-be91-4c0e-886a-9cc0a4378de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_keKPU40FNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_csv(newsqa_df, mode=\"split\"):\n",
        "  print('Total number of questions:', len(newsqa_df))\n",
        "  # Eliminate bad questions\n",
        "  bad_question_length = len(newsqa_df[newsqa_df['is_question_bad'] == '1.0'])\n",
        "  newsqa_df = newsqa_df[newsqa_df['is_question_bad'] != '1.0']\n",
        "  newsqa_df.index = range(len(newsqa_df))\n",
        "  print(\"You have eliminated {} bad questions.\".format(bad_question_length))\n",
        "  print(\"There are {} rows remaining.\".format(len(newsqa_df)))\n",
        "  # Remove \"(CNN) --\" patterns in the beginning of story text and eliminate rows where the min answer index becomes negative after removing (CNN) pattern\n",
        "  import re\n",
        "  cnn_list = []\n",
        "  indices_to_drop = []\n",
        "  for index, line in newsqa_df.iterrows():\n",
        "    if re.search('\\(CNN\\) +-', line['story_text']):\n",
        "      end_index = line['story_text'].index('(CNN)')\n",
        "      end_index += 5\n",
        "      while line['story_text'][end_index] == ' ':\n",
        "        end_index += 1\n",
        "      end_index += 2\n",
        "      while line['story_text'][end_index] == ' ':\n",
        "        end_index += 1\n",
        "      cnn = line['story_text'][line['story_text'].index('(CNN)'):end_index]\n",
        "      if cnn not in cnn_list:\n",
        "        cnn_list.append(cnn)\n",
        "      all_answers = line['answer_char_ranges'].split('|')\n",
        "      all_answers = [answer for answer in all_answers if answer != 'None']\n",
        "      stop = False\n",
        "      for i, answers in enumerate(all_answers):\n",
        "        answers = answers.split(',')\n",
        "        for j, answer in enumerate(answers):\n",
        "          answer = answer.split(':')\n",
        "          if int(answer[0])-(line['story_text'].index(cnn)+len(cnn)) < 0:\n",
        "            stop = True\n",
        "            indices_to_drop.append(index)\n",
        "            break\n",
        "        if stop:\n",
        "          break\n",
        "    else:\n",
        "      indices_to_drop.append(index)\n",
        "  print(\"Here are the eliminated (CNN) patterns:\", cnn_list)\n",
        "  newsqa_df = newsqa_df.drop(newsqa_df.index[indices_to_drop])\n",
        "  newsqa_df.index = range(len(newsqa_df))\n",
        "  print(\"You have eliminated {} rows where the min answer index was negative after removing the (CNN) patterns.\".format(len(indices_to_drop)))\n",
        "  print(\"There are {} rows remaining.\".format(len(newsqa_df)))\n",
        "  # Preprocess according to tokenization mode\n",
        "  if mode == \"spacy\":\n",
        "    import spacy\n",
        "    nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner', 'textcat'])\n",
        "  elif mode == \"bert\":\n",
        "    !pip install transformers\n",
        "    from transformers import BertTokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  print(\"Preprocessing...\")\n",
        "  answer1_min_char_index = []\n",
        "  answer1_max_char_index = []\n",
        "  answer1_char = []\n",
        "  answer2_min_char_index = []\n",
        "  answer2_max_char_index = []\n",
        "  answer2_char = []\n",
        "  answer1_min_word_index = []\n",
        "  answer1_max_word_index = []\n",
        "  answer1_word = []\n",
        "  answer2_min_word_index = []\n",
        "  answer2_max_word_index = []\n",
        "  answer2_word = []\n",
        "  new_story_text = []\n",
        "  for index, line in newsqa_df.iterrows():\n",
        "    all_answers = line['answer_char_ranges'].split('|')\n",
        "    all_answers = [answer for answer in all_answers if answer != 'None']\n",
        "    if len(all_answers) < 2:\n",
        "      answer2_min_char_index.append('None')\n",
        "      answer2_max_char_index.append('None')\n",
        "      answer2_char.append('None')\n",
        "      answer2_min_word_index.append('None')\n",
        "      answer2_max_word_index.append('None')\n",
        "      answer2_word.append('None')\n",
        "      if len(all_answers) == 0:\n",
        "        answer1_min_char_index.append('None')\n",
        "        answer1_max_char_index.append('None')\n",
        "        answer1_char.append('None')\n",
        "        answer1_min_word_index.append('None')\n",
        "        answer1_max_word_index.append('None')\n",
        "        answer1_word.append('None')\n",
        "    else:\n",
        "      all_answers = all_answers[:2]\n",
        "    for cnn in cnn_list:\n",
        "      if cnn in line['story_text']:\n",
        "        for i, answers in enumerate(all_answers):\n",
        "          min_answers = ''\n",
        "          max_answers = ''\n",
        "          answers = answers.split(',')\n",
        "          for j, answer in enumerate(answers):\n",
        "            answer = answer.split(':')\n",
        "            answer[0] = int(answer[0])-(line['story_text'].index(cnn)+len(cnn))\n",
        "            min_answers += str(answer[0])\n",
        "            answer[1] = int(answer[1])-(line['story_text'].index(cnn)+len(cnn))\n",
        "            max_answers += str(answer[1]-1)\n",
        "            answers[j] = str(answer[0])+':'+str(answer[1]-1)\n",
        "            if j < len(answers) - 1:\n",
        "              answers[j] += ','\n",
        "              min_answers += ','\n",
        "              max_answers += ','\n",
        "          all_answers[i] = ''.join(answers)\n",
        "          if i == 0:\n",
        "            answer1_min_char_index.append(min_answers)\n",
        "            answer1_max_char_index.append(max_answers)\n",
        "          elif i == 1:\n",
        "            answer2_min_char_index.append(min_answers)\n",
        "            answer2_max_char_index.append(max_answers)\n",
        "        line['story_text'] = line['story_text'][line['story_text'].index(cnn)+len(cnn):]\n",
        "    new_story_text.append(line['story_text'])\n",
        "    for i, answers in enumerate(all_answers):\n",
        "      char_result = ''\n",
        "      min_answers = ''\n",
        "      max_answers = ''\n",
        "      word_result = ''\n",
        "      answers = answers.split(',')\n",
        "      for j, answer in enumerate(answers):\n",
        "        answer = answer.split(':')\n",
        "        char_result += line['story_text'][int(answer[0]):int(answer[1])+1]\n",
        "        story_text_split = line['story_text'].split(line['story_text'][int(answer[0]):int(answer[1])+1])\n",
        "        if mode == 'split':\n",
        "          before_split = story_text_split[0].split()\n",
        "          min_word_index = len(before_split)\n",
        "          answer_split = line['story_text'][int(answer[0]):int(answer[1])+1].split()\n",
        "          max_word_index = min_word_index + len(answer_split)\n",
        "          word_result += ' '.join(line['story_text'].split()[min_word_index:max_word_index]) + ' '\n",
        "        elif mode == 'spacy':\n",
        "          before_split = nlp(story_text_split[0])\n",
        "          before_tokens = [token.text for token in before_split]\n",
        "          min_word_index = len(before_tokens)\n",
        "          answer_split = nlp(line['story_text'][int(answer[0]):int(answer[1])+1])\n",
        "          answer_tokens = [token.text for token in answer_split]\n",
        "          max_word_index = min_word_index + len(answer_tokens)\n",
        "          word_split = nlp(line['story_text'])\n",
        "          word_tokens = [token.text for token in word_split]\n",
        "          word_result += ' '.join(word_tokens[min_word_index:max_word_index]) + ' '\n",
        "        elif mode == 'bert':\n",
        "          before_split = tokenizer.tokenize(story_text_split[0])\n",
        "          min_word_index = len(before_split)\n",
        "          answer_split = tokenizer.tokenize(line['story_text'][int(answer[0]):int(answer[1])+1])\n",
        "          max_word_index = min_word_index + len(answer_split)\n",
        "          word_split = tokenizer.tokenize(line['story_text'])\n",
        "          final_word_split = []\n",
        "          for token in word_split[min_word_index:max_word_index]:\n",
        "            if token[:2] == '##':\n",
        "              final_word_split.append(token[2:])\n",
        "            else:\n",
        "              final_word_split.append(token)\n",
        "          word_result += ' '.join(final_word_split) + ' '\n",
        "        min_answers += str(min_word_index)\n",
        "        max_answers += str(max_word_index-1)\n",
        "        if j < len(answers) - 1:\n",
        "          min_answers += ','\n",
        "          max_answers += ','\n",
        "      if i == 0:\n",
        "        answer1_char.append(char_result)\n",
        "        answer1_min_word_index.append(min_answers)\n",
        "        answer1_max_word_index.append(max_answers)\n",
        "        answer1_word.append(word_result)\n",
        "      elif i == 1:\n",
        "        answer2_char.append(char_result)\n",
        "        answer2_min_word_index.append(min_answers)\n",
        "        answer2_max_word_index.append(max_answers)\n",
        "        answer2_word.append(word_result)\n",
        "  newsqa_df = newsqa_df.drop('answer_char_ranges', axis=1)\n",
        "  newsqa_df['char_start_index_1'] = answer1_min_char_index\n",
        "  newsqa_df['char_end_index_1'] = answer1_max_char_index\n",
        "  newsqa_df['char_text_1'] = answer1_char\n",
        "  newsqa_df['char_start_index_2'] = answer2_min_char_index\n",
        "  newsqa_df['char_end_index_2'] = answer2_max_char_index\n",
        "  newsqa_df['char_text_2'] = answer2_char\n",
        "  newsqa_df['word_start_index_1'] = answer1_min_word_index\n",
        "  newsqa_df['word_end_index_1'] = answer1_max_word_index\n",
        "  newsqa_df['word_text_1'] = answer1_word\n",
        "  newsqa_df['word_start_index_2'] = answer2_min_word_index\n",
        "  newsqa_df['word_end_index_2'] = answer2_max_word_index\n",
        "  newsqa_df['word_text_2'] = answer2_word\n",
        "  newsqa_df['story_text'] = new_story_text\n",
        "  # Remove rows where the char answer does not match the word answer\n",
        "  indices_to_drop = []\n",
        "  for index, line in newsqa_df.iterrows():\n",
        "    real_char_answer_1 = [a.lower() for a in newsqa_df['char_text_1'][index] if a not in ' \\n']\n",
        "    real_word_answer_1 = [a.lower() for a in newsqa_df['word_text_1'][index] if a not in ' \\n']\n",
        "    real_char_answer_2 = [a.lower() for a in newsqa_df['char_text_2'][index] if a not in ' \\n']\n",
        "    real_word_answer_2 = [a.lower() for a in newsqa_df['word_text_2'][index] if a not in ' \\n']\n",
        "    if real_char_answer_1 != real_word_answer_1 or real_char_answer_2 != real_word_answer_2:\n",
        "      indices_to_drop.append(index)\n",
        "  newsqa_df = newsqa_df.drop(newsqa_df.index[indices_to_drop])\n",
        "  newsqa_df.index = range(len(newsqa_df))\n",
        "  print(\"You have eliminated {} rows where the char answer did not match the word answer.\".format(len(indices_to_drop)))\n",
        "  print(\"There are {} rows remaining.\".format(len(newsqa_df)))\n",
        "  return newsqa_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9US2cWjIfn98",
        "colab_type": "code",
        "outputId": "f2ded34c-3935-4989-d285-c2664dd1fea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "newsqa_df = pd.read_csv('gdrive/Shared drives/CIS 700-1 Final Project/Data/combined-newsqa-data-v1.csv')\n",
        "newsqa_df = preprocess_csv(newsqa_df, \"spacy\")\n",
        "newsqa_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of questions: 119633\n",
            "You have eliminated 6646 bad questions.\n",
            "There are 112987 rows remaining.\n",
            "Here are the eliminated (CNN) patterns: ['(CNN) -- ', '(CNN)  -- ', '(CNN)      -- ', '(CNN) --  ', '(CNN) --   ', '(CNN)  --  ', '(CNN)    -- ', '(CNN)   -- ', '(CNN) --     ', '(CNN)  --   ']\n",
            "You have eliminated 10713 rows where the min answer index was negative after removing the (CNN) patterns.\n",
            "There are 102274 rows remaining.\n",
            "You have eliminated 544 rows where the char answer did not match the word answer.\n",
            "There are 101730 rows remaining.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>question</th>\n",
              "      <th>is_answer_absent</th>\n",
              "      <th>is_question_bad</th>\n",
              "      <th>validated_answers</th>\n",
              "      <th>story_text</th>\n",
              "      <th>char_start_index_1</th>\n",
              "      <th>char_end_index_1</th>\n",
              "      <th>char_text_1</th>\n",
              "      <th>char_start_index_2</th>\n",
              "      <th>char_end_index_2</th>\n",
              "      <th>char_text_2</th>\n",
              "      <th>word_start_index_1</th>\n",
              "      <th>word_end_index_1</th>\n",
              "      <th>word_text_1</th>\n",
              "      <th>word_start_index_2</th>\n",
              "      <th>word_end_index_2</th>\n",
              "      <th>word_text_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
              "      <td>What was the amount of children murdered?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
              "      <td>A high court in northern India on Friday acqui...</td>\n",
              "      <td>268</td>\n",
              "      <td>270</td>\n",
              "      <td>19</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>19</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./cnn/stories/c48228a52f26aca65c31fad273e66164...</td>\n",
              "      <td>Where was one employee killed?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fighting in the volatile Sudanese region of Da...</td>\n",
              "      <td>25</td>\n",
              "      <td>50</td>\n",
              "      <td>Sudanese region of Darfur</td>\n",
              "      <td>1601</td>\n",
              "      <td>1608</td>\n",
              "      <td>Seleia,</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>Sudanese region of Darfur</td>\n",
              "      <td>302</td>\n",
              "      <td>303</td>\n",
              "      <td>Seleia ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./cnn/stories/c65ed85800e4535f4bbbfa2c34d7d963...</td>\n",
              "      <td>who did say South Africa did not issue a visa ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"839:853\": 1, \"103:127\": 2}</td>\n",
              "      <td>Miffed by a visa delay that led the Dalai Lama...</td>\n",
              "      <td>81</td>\n",
              "      <td>104</td>\n",
              "      <td>Archbishop Desmond Tutu</td>\n",
              "      <td>92</td>\n",
              "      <td>104</td>\n",
              "      <td>Desmond Tutu</td>\n",
              "      <td>18</td>\n",
              "      <td>20</td>\n",
              "      <td>Archbishop Desmond Tutu</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Desmond Tutu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./cnn/stories/0cf66b646e9b32076513c050edf32a79...</td>\n",
              "      <td>How many years old was the businessman?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>England international footballer Steven Gerrar...</td>\n",
              "      <td>528</td>\n",
              "      <td>539</td>\n",
              "      <td>29-year-old</td>\n",
              "      <td>528</td>\n",
              "      <td>539</td>\n",
              "      <td>29-year-old</td>\n",
              "      <td>99</td>\n",
              "      <td>101</td>\n",
              "      <td>29-year - old</td>\n",
              "      <td>99</td>\n",
              "      <td>101</td>\n",
              "      <td>29-year - old</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./cnn/stories/13012604e3203c18df09289dfedd14cd...</td>\n",
              "      <td>What frightened the families?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"688:791\": 2, \"690:742\": 1}</td>\n",
              "      <td>At least 6,000 Christians have fled the northe...</td>\n",
              "      <td>666</td>\n",
              "      <td>717</td>\n",
              "      <td>series of killings and threats by Muslim extre...</td>\n",
              "      <td>664</td>\n",
              "      <td>766</td>\n",
              "      <td>a series of killings and threats by Muslim ext...</td>\n",
              "      <td>125</td>\n",
              "      <td>132</td>\n",
              "      <td>series of killings and threats by Muslim extre...</td>\n",
              "      <td>124</td>\n",
              "      <td>143</td>\n",
              "      <td>a series of killings and threats by Muslim ext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101725</th>\n",
              "      <td>./cnn/stories/7c06e091d7294c87ba42df50008783d9...</td>\n",
              "      <td>what is this pattern is all about?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{\"1624:1829\": 2}</td>\n",
              "      <td>They feature characters such as hat-wearing ca...</td>\n",
              "      <td>1561,1580,1615,1821,2171,2192,2317</td>\n",
              "      <td>1571,1602,1819,1894,2187,2312,2406</td>\n",
              "      <td>reassuring of 'home, away, home,' \"The basic p...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>317,319,332,380,463,469,494</td>\n",
              "      <td>317,327,379,394,467,492,514</td>\n",
              "      <td>reassuring of ' home , away , home , ' \" The b...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101726</th>\n",
              "      <td>./cnn/stories/4424c8580952975a3e367176a215c787...</td>\n",
              "      <td>is toyota under fire issues on sticking gas pe...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Without issuing a recall of its iconic Prius h...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101727</th>\n",
              "      <td>./cnn/stories/7b2b414d8cbc968f4df05bcefb2f9f0f...</td>\n",
              "      <td>what are the men being detained for</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"2386:2435\": 2}</td>\n",
              "      <td>Three of five Americans contractors detained i...</td>\n",
              "      <td>2363</td>\n",
              "      <td>2411</td>\n",
              "      <td>suspects in connection with Kitterman's slayin...</td>\n",
              "      <td>1123</td>\n",
              "      <td>1143</td>\n",
              "      <td>\"illegal substances\"</td>\n",
              "      <td>444</td>\n",
              "      <td>452</td>\n",
              "      <td>suspects in connection with Kitterman 's slayi...</td>\n",
              "      <td>214</td>\n",
              "      <td>217</td>\n",
              "      <td>\" illegal substances \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101728</th>\n",
              "      <td>./cnn/stories/4566e90ca5e65f0323c41319030ca434...</td>\n",
              "      <td>In what year didIvory Coast exit in group stag...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Didier Drogba is backing his Ivory Coast team ...</td>\n",
              "      <td>1250</td>\n",
              "      <td>1254</td>\n",
              "      <td>2006</td>\n",
              "      <td>1250</td>\n",
              "      <td>1254</td>\n",
              "      <td>2006</td>\n",
              "      <td>257</td>\n",
              "      <td>257</td>\n",
              "      <td>2006</td>\n",
              "      <td>257</td>\n",
              "      <td>257</td>\n",
              "      <td>2006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101729</th>\n",
              "      <td>./cnn/stories/3666f90c41e7c7f184b5d237fa84fc07...</td>\n",
              "      <td>Where was Jackson born?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The mayor of Gary, Indiana, and Michael Jackso...</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>Gary, Indiana,</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>Gary, Indiana,</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Gary , Indiana ,</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>Gary , Indiana ,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101730 rows Ã— 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 story_id  ...                                        word_text_2\n",
              "0       ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...  ...                                               None\n",
              "1       ./cnn/stories/c48228a52f26aca65c31fad273e66164...  ...                                          Seleia , \n",
              "2       ./cnn/stories/c65ed85800e4535f4bbbfa2c34d7d963...  ...                                      Desmond Tutu \n",
              "3       ./cnn/stories/0cf66b646e9b32076513c050edf32a79...  ...                                     29-year - old \n",
              "4       ./cnn/stories/13012604e3203c18df09289dfedd14cd...  ...  a series of killings and threats by Muslim ext...\n",
              "...                                                   ...  ...                                                ...\n",
              "101725  ./cnn/stories/7c06e091d7294c87ba42df50008783d9...  ...                                               None\n",
              "101726  ./cnn/stories/4424c8580952975a3e367176a215c787...  ...                                               None\n",
              "101727  ./cnn/stories/7b2b414d8cbc968f4df05bcefb2f9f0f...  ...                            \" illegal substances \" \n",
              "101728  ./cnn/stories/4566e90ca5e65f0323c41319030ca434...  ...                                              2006 \n",
              "101729  ./cnn/stories/3666f90c41e7c7f184b5d237fa84fc07...  ...                                  Gary , Indiana , \n",
              "\n",
              "[101730 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTz8ljsHeNTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsqa_df.to_csv('gdrive/Shared drives/CIS 700-1 Final Project/Data/combined-newsqa-data-v2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U6KD92wedgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsqa_df[:10].to_csv('gdrive/Shared drives/CIS 700-1 Final Project/Data/mini-combined-newsqa-data-v2.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGaoi5__Mx0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_json(data, mode=\"split\", only_answerable=False):\n",
        "  # Convert json data to csv format\n",
        "  newsqa_data2 = {'story_id': [], 'question': [], 'answer_char_ranges': [], 'is_answer_absent': [], 'is_question_bad': [], 'validated_answers': [], 'story_text': []}\n",
        "  for story in data['data']:\n",
        "    for question in story['questions']:\n",
        "      newsqa_data2['story_id'].append(story['storyId'])\n",
        "      newsqa_data2['question'].append(question['q'])\n",
        "      if 'badQuestion' in question['consensus'] and question['consensus']['badQuestion'] == True or 'noAnswer' in question['consensus'] and question['consensus']['noAnswer'] == True:\n",
        "        newsqa_data2['answer_char_ranges'].append('None')\n",
        "      else:\n",
        "        newsqa_data2['answer_char_ranges'].append(str(question['consensus']['s'])+':'+str(question['consensus']['e']))\n",
        "      newsqa_data2['is_answer_absent'].append(str(question['isAnswerAbsent']))\n",
        "      if 'isQuestionBad' not in question:\n",
        "        newsqa_data2['is_question_bad'].append('0.0')\n",
        "      else:\n",
        "        newsqa_data2['is_question_bad'].append(str(question['isQuestionBad']))\n",
        "      validated_answers = ''\n",
        "      if 'validatedAnswers' not in question:\n",
        "        validated_answers = 'NaN'\n",
        "      else:\n",
        "        num_answer_found = False\n",
        "        for index, answer in enumerate(question['validatedAnswers']):\n",
        "          if index == 0:\n",
        "            validated_answers += '{'\n",
        "          if 's' in answer and 'e' in answer:\n",
        "            validated_answers += '\\\"' + str(answer['s']) + ':' + str(answer['e']) + '\\\": ' + str(answer['count'])\n",
        "            num_answer_found = True\n",
        "          elif 'badQuestion' in answer or 'noAnswer' in answer:\n",
        "            validated_answers += '\\\"none\\\": ' + str(answer['count'])\n",
        "          if index < len(question['validatedAnswers'])-1:\n",
        "            validated_answers += ', '\n",
        "          else:\n",
        "            validated_answers += '}'\n",
        "        if not num_answer_found:\n",
        "          validated_answers = 'NaN'\n",
        "      newsqa_data2['validated_answers'].append(validated_answers)\n",
        "      newsqa_data2['story_text'].append(story['text'])\n",
        "  newsqa_df2 = pd.DataFrame.from_dict(newsqa_data2)\n",
        "  print('Total number of questions:', len(newsqa_df2))\n",
        "  # Eliminate bad questions\n",
        "  bad_question_length = len(newsqa_df2[newsqa_df2['is_question_bad'] == '1.0'])\n",
        "  newsqa_df2 = newsqa_df2[newsqa_df2['is_question_bad'] != '1.0']\n",
        "  newsqa_df2.index = range(len(newsqa_df2))\n",
        "  print(\"You have eliminated {} bad questions.\".format(bad_question_length))\n",
        "  print(\"There are {} rows remaining.\".format(len(newsqa_df2)))\n",
        "  # Remove \"(CNN) --\" patterns in the beginning of story text and eliminate rows where the min answer index becomes negative after removing (CNN) pattern\n",
        "  import re\n",
        "  cnn_list = []\n",
        "  indices_to_drop = []\n",
        "  for index, line in newsqa_df2.iterrows():\n",
        "    if re.search('\\(CNN\\) +-', line['story_text']):\n",
        "      end_index = line['story_text'].index('(CNN)')\n",
        "      end_index += 5\n",
        "      while line['story_text'][end_index] == ' ':\n",
        "        end_index += 1\n",
        "      end_index += 2\n",
        "      while line['story_text'][end_index] == ' ':\n",
        "        end_index += 1\n",
        "      cnn = line['story_text'][line['story_text'].index('(CNN)'):end_index]\n",
        "      if cnn not in cnn_list:\n",
        "        cnn_list.append(cnn)\n",
        "      if line['answer_char_ranges'] != 'None':\n",
        "        answer = line['answer_char_ranges'].split(':')\n",
        "        if int(answer[0])-(line['story_text'].index(cnn)+len(cnn)) < 0:\n",
        "            indices_to_drop.append(index)\n",
        "    else:\n",
        "      indices_to_drop.append(index)\n",
        "  print(\"Here are the eliminated (CNN) patterns:\", cnn_list)\n",
        "  newsqa_df2 = newsqa_df2.drop(newsqa_df2.index[indices_to_drop])\n",
        "  newsqa_df2.index = range(len(newsqa_df2))\n",
        "  print(\"You have eliminated {} rows where the min answer index was negative after removing the (CNN) patterns.\".format(len(indices_to_drop)))\n",
        "  print(\"There are {} rows remaining.\".format(len(newsqa_df2)))\n",
        "  # Preprocess according to tokenization mode\n",
        "  if mode == \"spacy\":\n",
        "    import spacy\n",
        "    nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner', 'textcat'])\n",
        "  elif mode == \"bert\":\n",
        "    !pip install transformers\n",
        "    from transformers import BertTokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  print(\"Preprocessing...\")\n",
        "  answer_min_char_index = []\n",
        "  answer_max_char_index = []\n",
        "  answer_char = []\n",
        "  answer_min_word_index = []\n",
        "  answer_max_word_index = []\n",
        "  answer_word = []\n",
        "  new_story_text = []\n",
        "  for index, line in newsqa_df2.iterrows():\n",
        "    if line['answer_char_ranges'] == 'None':\n",
        "      answer_min_char_index.append('None')\n",
        "      answer_max_char_index.append('None')\n",
        "      answer_char.append('None')\n",
        "      answer_min_word_index.append('None')\n",
        "      answer_max_word_index.append('None')\n",
        "      answer_word.append('None')\n",
        "    for cnn in cnn_list:\n",
        "      if cnn in line['story_text']:\n",
        "        if line['answer_char_ranges'] != 'None':\n",
        "          answer = line['answer_char_ranges'].split(':')\n",
        "          answer[0] = int(answer[0])-(line['story_text'].index(cnn)+len(cnn))\n",
        "          answer[1] = int(answer[1])-(line['story_text'].index(cnn)+len(cnn))\n",
        "          line['answer_char_ranges'] = str(answer[0])+':'+str(answer[1]-1)\n",
        "          answer_min_char_index.append(str(answer[0]))\n",
        "          answer_max_char_index.append(str(answer[1]-1))\n",
        "        line['story_text'] = line['story_text'][line['story_text'].index(cnn)+len(cnn):]\n",
        "    new_story_text.append(line['story_text'])\n",
        "    if line['answer_char_ranges'] == 'None':\n",
        "      continue\n",
        "    answer = line['answer_char_ranges'].split(':')\n",
        "    char_result = line['story_text'][int(answer[0]):int(answer[1])+1]\n",
        "    story_text_split = line['story_text'].split(line['story_text'][int(answer[0]):int(answer[1])+1])\n",
        "    if mode == 'split':\n",
        "      before_split = story_text_split[0].split()\n",
        "      min_word_index = len(before_split)\n",
        "      answer_split = line['story_text'][int(answer[0]):int(answer[1])+1].split()\n",
        "      max_word_index = min_word_index + len(answer_split)\n",
        "      word_result = ' '.join(line['story_text'].split()[min_word_index:max_word_index]) + ' '\n",
        "    elif mode == 'spacy':\n",
        "      before_split = nlp(story_text_split[0])\n",
        "      before_tokens = [token.text for token in before_split]\n",
        "      min_word_index = len(before_tokens)\n",
        "      answer_split = nlp(line['story_text'][int(answer[0]):int(answer[1])+1])\n",
        "      answer_tokens = [token.text for token in answer_split]\n",
        "      max_word_index = min_word_index + len(answer_tokens)\n",
        "      word_split = nlp(line['story_text'])\n",
        "      word_tokens = [token.text for token in word_split]\n",
        "      word_result = ' '.join(word_tokens[min_word_index:max_word_index]) + ' '\n",
        "    elif mode == 'bert':\n",
        "      before_split = tokenizer.tokenize(story_text_split[0])\n",
        "      min_word_index = len(before_split)\n",
        "      answer_split = tokenizer.tokenize(line['story_text'][int(answer[0]):int(answer[1])+1])\n",
        "      max_word_index = min_word_index + len(answer_split)\n",
        "      word_split = tokenizer.tokenize(line['story_text'])\n",
        "      final_word_split = []\n",
        "      for token in word_split[min_word_index:max_word_index]:\n",
        "        if token[:2] == '##':\n",
        "          final_word_split.append(token[2:])\n",
        "        else:\n",
        "          final_word_split.append(token)\n",
        "      word_result = ' '.join(final_word_split) + ' '\n",
        "    min_answers = str(min_word_index)\n",
        "    max_answers = str(max_word_index-1)\n",
        "    answer_char.append(char_result)\n",
        "    answer_min_word_index.append(str(min_word_index))\n",
        "    answer_max_word_index.append(str(max_word_index-1))\n",
        "    answer_word.append(word_result)\n",
        "  newsqa_df2 = newsqa_df2.drop('answer_char_ranges', axis=1)\n",
        "  newsqa_df2['char_start_index'] = answer_min_char_index\n",
        "  newsqa_df2['char_end_index'] = answer_max_char_index\n",
        "  newsqa_df2['char_text'] = answer_char\n",
        "  newsqa_df2['word_start_index'] = answer_min_word_index\n",
        "  newsqa_df2['word_end_index'] = answer_max_word_index\n",
        "  newsqa_df2['word_text'] = answer_word\n",
        "  newsqa_df2['story_text'] = new_story_text\n",
        "  # Remove rows where the char answer does not match the word answer\n",
        "  indices_to_drop = []\n",
        "  for index, line in newsqa_df2.iterrows():\n",
        "    real_char_answer = [a.lower() for a in newsqa_df2['char_text'][index] if a not in ' \\n']\n",
        "    real_word_answer = [a.lower() for a in newsqa_df2['word_text'][index] if a not in ' \\n']\n",
        "    if real_char_answer != real_word_answer:\n",
        "      indices_to_drop.append(index)\n",
        "  newsqa_df2 = newsqa_df2.drop(newsqa_df2.index[indices_to_drop])\n",
        "  newsqa_df2.index = range(len(newsqa_df2))\n",
        "  print(\"You have eliminated {} rows where the char answer did not match the word answer.\".format(len(indices_to_drop)))\n",
        "  print(\"There are {} rows remaining.\".format(len(newsqa_df2)))\n",
        "  if only_answerable:\n",
        "    newsqa_df2 = newsqa_df2[newsqa_df2['char_text'] != 'None']\n",
        "    newsqa_df2.index = range(len(newsqa_df2))\n",
        "    print(\"There are {} answerable questions remaining.\".format(len(newsqa_df2)))\n",
        "  return newsqa_df2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDY8v3ym_AkR",
        "colab_type": "code",
        "outputId": "1a3da89a-9741-43df-97c8-4b64ed0dac53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import json\n",
        "with open('gdrive/Shared drives/CIS 700-1 Final Project/Data/combined-newsqa-data-v1.json') as f:\n",
        "  data = json.load(f)\n",
        "newsqa_df2 = preprocess_json(data, \"split\", True)\n",
        "newsqa_df2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of questions: 119633\n",
            "You have eliminated 6646 bad questions.\n",
            "There are 112987 rows remaining.\n",
            "Here are the eliminated (CNN) patterns: ['(CNN) -- ', '(CNN)  -- ', '(CNN)      -- ', '(CNN) --  ', '(CNN) --   ', '(CNN) --     ', '(CNN)  --  ', '(CNN)    -- ', '(CNN)   -- ', '(CNN)  --   ']\n",
            "You have eliminated 9956 rows where the min answer index was negative after removing the (CNN) patterns.\n",
            "There are 103031 rows remaining.\n",
            "Preprocessing...\n",
            "You have eliminated 121 rows where the char answer did not match the word answer.\n",
            "There are 102910 rows remaining.\n",
            "There are 77693 answerable questions remaining.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>story_id</th>\n",
              "      <th>question</th>\n",
              "      <th>is_answer_absent</th>\n",
              "      <th>is_question_bad</th>\n",
              "      <th>validated_answers</th>\n",
              "      <th>story_text</th>\n",
              "      <th>char_start_index</th>\n",
              "      <th>char_end_index</th>\n",
              "      <th>char_text</th>\n",
              "      <th>word_start_index</th>\n",
              "      <th>word_end_index</th>\n",
              "      <th>word_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
              "      <td>What was the amount of children murdered?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"none\": 1, \"294:297\": 2}</td>\n",
              "      <td>A high court in northern India on Friday acqui...</td>\n",
              "      <td>268</td>\n",
              "      <td>270</td>\n",
              "      <td>19</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
              "      <td>When was Pandher sentenced to death?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A high court in northern India on Friday acqui...</td>\n",
              "      <td>235</td>\n",
              "      <td>244</td>\n",
              "      <td>February.\\n</td>\n",
              "      <td>42</td>\n",
              "      <td>42</td>\n",
              "      <td>February.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
              "      <td>The court aquitted Moninder Singh Pandher of w...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"624:640\": 2}</td>\n",
              "      <td>A high court in northern India on Friday acqui...</td>\n",
              "      <td>598</td>\n",
              "      <td>613</td>\n",
              "      <td>rape and murder</td>\n",
              "      <td>104</td>\n",
              "      <td>106</td>\n",
              "      <td>rape and murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
              "      <td>who was acquitted</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A high court in northern India on Friday acqui...</td>\n",
              "      <td>169</td>\n",
              "      <td>191</td>\n",
              "      <td>Moninder Singh Pandher</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>Moninder Singh Pandher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>./cnn/stories/42d01e187213e86f5fe617fe32e716ff...</td>\n",
              "      <td>who was sentenced</td>\n",
              "      <td>0.33333333333299997</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"195:218\": 2}</td>\n",
              "      <td>A high court in northern India on Friday acqui...</td>\n",
              "      <td>169</td>\n",
              "      <td>191</td>\n",
              "      <td>Moninder Singh Pandher</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>Moninder Singh Pandher</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77688</th>\n",
              "      <td>./cnn/stories/a065926962ac486d89602e4e7d774f47...</td>\n",
              "      <td>Charges were dropped against which professor?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333333333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The commissioner of the Cambridge, Massachuset...</td>\n",
              "      <td>161</td>\n",
              "      <td>183</td>\n",
              "      <td>Henry Louis Gates Jr.,</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>Henry Louis Gates Jr.,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77689</th>\n",
              "      <td>./cnn/stories/a065926962ac486d89602e4e7d774f47...</td>\n",
              "      <td>What did the officer say?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"4928:5076\": 2}</td>\n",
              "      <td>The commissioner of the Cambridge, Massachuset...</td>\n",
              "      <td>4919</td>\n",
              "      <td>5066</td>\n",
              "      <td>\"While I was led to believe that Gates was law...</td>\n",
              "      <td>772</td>\n",
              "      <td>797</td>\n",
              "      <td>\"While I was led to believe that Gates was law...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77690</th>\n",
              "      <td>./cnn/stories/a065926962ac486d89602e4e7d774f47...</td>\n",
              "      <td>What happened to the professor?</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{\"751:897\": 2}</td>\n",
              "      <td>The commissioner of the Cambridge, Massachuset...</td>\n",
              "      <td>742</td>\n",
              "      <td>887</td>\n",
              "      <td>Gates was arrested for disorderly conduct afte...</td>\n",
              "      <td>118</td>\n",
              "      <td>141</td>\n",
              "      <td>Gates was arrested for disorderly conduct afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77691</th>\n",
              "      <td>./cnn/stories/52a68e9f8f4d36a669e207d66273a2d7...</td>\n",
              "      <td>what did cooey say</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>An Ohio death row inmate who says he is too ov...</td>\n",
              "      <td>34</td>\n",
              "      <td>69</td>\n",
              "      <td>he is too overweight to be executed</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>he is too overweight to be executed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77692</th>\n",
              "      <td>./cnn/stories/52a68e9f8f4d36a669e207d66273a2d7...</td>\n",
              "      <td>what are they going to address</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>An Ohio death row inmate who says he is too ov...</td>\n",
              "      <td>581</td>\n",
              "      <td>685</td>\n",
              "      <td>the larger constitutional claims over when a c...</td>\n",
              "      <td>95</td>\n",
              "      <td>109</td>\n",
              "      <td>the larger constitutional claims over when a c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>77693 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                story_id  ...                                          word_text\n",
              "0      ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...  ...                                                19 \n",
              "1      ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...  ...                                         February. \n",
              "2      ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...  ...                                   rape and murder \n",
              "3      ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...  ...                            Moninder Singh Pandher \n",
              "4      ./cnn/stories/42d01e187213e86f5fe617fe32e716ff...  ...                            Moninder Singh Pandher \n",
              "...                                                  ...  ...                                                ...\n",
              "77688  ./cnn/stories/a065926962ac486d89602e4e7d774f47...  ...                            Henry Louis Gates Jr., \n",
              "77689  ./cnn/stories/a065926962ac486d89602e4e7d774f47...  ...  \"While I was led to believe that Gates was law...\n",
              "77690  ./cnn/stories/a065926962ac486d89602e4e7d774f47...  ...  Gates was arrested for disorderly conduct afte...\n",
              "77691  ./cnn/stories/52a68e9f8f4d36a669e207d66273a2d7...  ...               he is too overweight to be executed \n",
              "77692  ./cnn/stories/52a68e9f8f4d36a669e207d66273a2d7...  ...  the larger constitutional claims over when a c...\n",
              "\n",
              "[77693 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4INx4K5hSjZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsqa_df2.to_csv('gdrive/Shared drives/CIS 700-1 Final Project/Data/combined-newsqa-data-v2-json.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SYNTbA_tGPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newsqa_df2[:10].to_csv('gdrive/Shared drives/CIS 700-1 Final Project/Data/mini-combined-newsqa-data-v2-json.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}